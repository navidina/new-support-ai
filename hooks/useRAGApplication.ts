
import { useState, useRef, useEffect } from 'react';
import { Message, DocumentStatus, KnowledgeChunk, Conversation, FineTuningRecord, PipelineData } from '../types';
import { 
    processQuery, 
    parseFiles, 
    loadChunksFromDB, 
    clearDatabase, 
    exportDatabaseToBlob, 
    importDatabaseFromJson, 
    saveConversationToDB, 
    loadConversationsFromDB, 
    deleteConversationFromDB, 
    checkOllamaConnection, 
    getSettings,
    loadBenchmarkHistory,
    saveFineTuningRecord, 
    getFineTuningCount,   
    exportFineTuningDataset,
    loadTicketsFromDB,
    saveTicketsToDB,
    parseTicketFile,
    clearTicketsDB
} from '../services/mockBackend';

const INITIAL_MESSAGE: Message = {
  id: 'init-1',
  role: 'assistant',
  content: 'Ø³Ù„Ø§Ù…. Ø¯Ø³ØªÛŒØ§Ø± Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø±Ø§ÛŒØ§Ù† Ù‡Ù…â€ŒØ§ÙØ²Ø§ Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø³Øª.\n\nÙ„Ø·ÙØ§Ù‹ Ù¾ÙˆØ´Ù‡ Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù†ÛŒØ¯.',
  timestamp: new Date(),
};

const categoryLabels: Record<string, string> = {
    'back_office': 'Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ø§Ø±Ú¯Ø²Ø§Ø±ÛŒ',
    'online_trading': 'Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø¨Ø±Ø®Ø·',
    'portfolio_management': 'Ø³Ø¨Ø¯Ú¯Ø±Ø¯Ø§Ù†ÛŒ',
    'funds': 'ØµÙ†Ø¯ÙˆÙ‚â€ŒÙ‡Ø§ÛŒ Ø³Ø±Ù…Ø§ÛŒÙ‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ',
    'commodity_energy': 'Ø¨ÙˆØ±Ø³ Ú©Ø§Ù„Ø§ Ùˆ Ø§Ù†Ø±Ú˜ÛŒ',
    'troubleshooting': 'Ø¹ÛŒØ¨â€ŒÛŒØ§Ø¨ÛŒ',
    'operational_process': 'ÙØ±Ø¢ÛŒÙ†Ø¯Ù‡Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒÛŒ',
    'technical_infrastructure': 'ÙÙ†ÛŒ Ùˆ Ø²ÛŒØ±Ø³Ø§Ø®Øª',
    'general': 'Ø¹Ù…ÙˆÙ…ÛŒ'
};

export const useRAGApplication = () => {
    // --- State ---
    const [messages, setMessages] = useState<Message[]>([INITIAL_MESSAGE]);
    const [conversations, setConversations] = useState<Conversation[]>([]);
    const [currentChatId, setCurrentChatId] = useState<string>('new');
    const [inputText, setInputText] = useState('');
    const [isProcessing, setIsProcessing] = useState(false);
    // Explicitly track the TYPE of processing to prevent UI flickering during status updates
    const [processingType, setProcessingType] = useState<'file' | 'chat' | 'idle'>('idle');
    const [isDbLoading, setIsDbLoading] = useState(true);
    const [processingStatus, setProcessingStatus] = useState<string>('');
    const [customChunks, setCustomChunks] = useState<KnowledgeChunk[]>([]);
    const [ticketChunks, setTicketChunks] = useState<KnowledgeChunk[]>([]); // New state for isolated tickets
    const [docsList, setDocsList] = useState<DocumentStatus[]>([]);
    const [isOllamaOnline, setIsOllamaOnline] = useState<boolean>(false);
    const [lastBenchmarkScore, setLastBenchmarkScore] = useState<number | null>(null);
    const [fineTuningCount, setFineTuningCount] = useState(0); 
    
    // Toggle for General Knowledge (Simulated Internet Search)
    const [useWebSearch, setUseWebSearch] = useState(false);

    // Refs
    const isDbInitialized = useRef(false);
    const abortControllerRef = useRef<AbortController | null>(null);

    // --- Effects ---

    // 1. Health Check
    useEffect(() => {
        const checkHealth = async () => {
            const status = await checkOllamaConnection();
            setIsOllamaOnline(status);
        };
        checkHealth();
        const interval = setInterval(checkHealth, 5000);
        return () => clearInterval(interval);
    }, []);

    // 2. Initialize DB
    useEffect(() => {
        if (isDbInitialized.current) return;
        isDbInitialized.current = true; // Mark as initialized immediately to prevent double execution

        const initSystem = async () => {
            try {
                // Load General Knowledge
                const savedChunks = await loadChunksFromDB();
                if (savedChunks.length > 0) {
                    refreshStateFromChunks(savedChunks);
                }
                
                // Load Isolated Tickets
                const savedTickets = await loadTicketsFromDB();
                if (savedTickets.length > 0) {
                    setTicketChunks(savedTickets);
                }

                await loadHistory();
                await loadBenchmarkStats();
                await updateFineTuningCount(); 
            } catch (error) {
                console.error("Failed to load DB", error);
                // If the DB fails to load, we allow the app to continue so user can re-import or clear data
            } finally {
                setIsDbLoading(false);
            }
        };
        initSystem();
    }, []);

    // 3. Auto-save Conversation
    useEffect(() => {
        if (messages.length > 1 && currentChatId) {
            const firstUserMsg = messages.find(m => m.role === 'user');
            const title = firstUserMsg ? firstUserMsg.content.substring(0, 30) + (firstUserMsg.content.length > 30 ? '...' : '') : 'Ú¯ÙØªÚ¯ÙˆÛŒ Ø¬Ø¯ÛŒØ¯';
            const actualId = currentChatId === 'new' ? `chat-${Date.now()}` : currentChatId;
            
            if (currentChatId === 'new') {
                setCurrentChatId(actualId);
            }

            const conversation: Conversation = {
                id: actualId,
                title: title,
                messages: messages,
                lastUpdated: new Date()
            };

            saveConversationToDB(conversation).then(() => {
                loadHistory(); 
            });
        }
    }, [messages, currentChatId]);

    // --- Helpers ---

    const refreshStateFromChunks = (chunks: KnowledgeChunk[]) => {
        setCustomChunks(chunks);
        const docMap = new Map<string, number>();
        chunks.forEach(chunk => {
            const count = docMap.get(chunk.source.id) || 0;
            docMap.set(chunk.source.id, count + 1);
        });
        const reconstructedDocs: DocumentStatus[] = Array.from(docMap.entries()).map(([name, count]) => ({
            name,
            status: 'indexed',
            chunks: count
        }));
        setDocsList(reconstructedDocs);
    };

    const loadHistory = async () => {
        try {
            const convs = await loadConversationsFromDB();
            setConversations(convs);
        } catch (e) {
            console.error("Failed to load history", e);
        }
    };

    const loadBenchmarkStats = async () => {
        try {
            const runs = await loadBenchmarkHistory();
            if (runs.length > 0) {
                setLastBenchmarkScore(runs[0].avgScore);
            }
        } catch (e) {
            console.error("Failed to load benchmark stats", e);
        }
    };

    const updateFineTuningCount = async () => {
        const count = await getFineTuningCount();
        setFineTuningCount(count);
    };

    // --- Actions ---

    const performQuery = async (queryText: string, categoryFilter?: string, existingMsgId?: string) => {
        setIsProcessing(true);
        setProcessingType('chat');
        setProcessingStatus(categoryFilter ? `Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± Ø¨Ø®Ø´ ${categoryLabels[categoryFilter]}...` : (useWebSearch ? "Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± Ø¯Ø§Ù†Ø´ Ø¹Ù…ÙˆÙ…ÛŒ Ùˆ Ù…Ø³ØªÙ†Ø¯Ø§Øª..." : "ØªØ­Ù„ÛŒÙ„ Ø³ÙˆØ§Ù„ Ùˆ Ø¬Ø³ØªØ¬ÙˆÛŒ Ø¯Ù‚ÛŒÙ‚ Ø³Ø§Ø²Ù…Ø§Ù†ÛŒ..."));

        const responseMsgId = existingMsgId || 'msg-' + Date.now();
        
        // Only add if we didn't add it in the batch update (backward compatibility)
        if (!existingMsgId) {
            setMessages(prev => [...prev, {
                id: responseMsgId,
                role: 'assistant',
                content: '',
                timestamp: new Date(),
                isThinking: true
            }]);
        }

        try {
            // Get recent history for context-aware answers (last 6 messages excluding current)
            const history = messages
                .filter(m => !m.isThinking && m.id !== 'init-1')
                .slice(-6);

            // Fix: Provided 9 arguments to match the expected signature in services/search.ts and resolve argument count error.
            const response = await processQuery(
                queryText, 
                customChunks, 
                (pipelineData: PipelineData) => {
                    // Update UI with granular pipeline steps
                    setMessages(prev => prev.map(msg => {
                        if (msg.id === responseMsgId) {
                            return {
                                ...msg,
                                pipelineData: { ...msg.pipelineData, ...pipelineData } // MERGE previous data
                            };
                        }
                        return msg;
                    }));
                }, 
                categoryFilter,
                1,
                useWebSearch,
                history,
                undefined,
                false
            );

            if (response.error === "OLLAMA_CONNECTION_REFUSED") {
                const settings = getSettings();
                setMessages(prev => prev.map(msg => {
                    if (msg.id === responseMsgId) {
                        return {
                            ...msg,
                            content: `âŒ **Ø®Ø·Ø§ÛŒ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø³Ø±ÙˆØ± Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ**\n\nØ³ÛŒØ³ØªÙ… Ù‚Ø§Ø¯Ø± Ø¨Ù‡ Ø¨Ø±Ù‚Ø±Ø§Ø±ÛŒ Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Ollama Ø¯Ø± Ø¢Ø¯Ø±Ø³ \`${settings.ollamaBaseUrl}\` Ù†ÛŒØ³Øª.\n\nÙ„Ø·ÙØ§Ù‹ Ù…ÙˆØ§Ø±Ø¯ Ø²ÛŒØ± Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯:\nÛ±. Ø¢ÛŒØ§ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ollama Ø¨Ø§Ø² Ø§Ø³ØªØŸ\nÛ². Ø¢ÛŒØ§ Ø¯Ø³ØªÙˆØ± \`ollama serve\` Ø¯Ø± ØªØ±Ù…ÛŒÙ†Ø§Ù„ Ø§Ø¬Ø±Ø§ Ø´Ø¯Ù‡ Ø§Ø³ØªØŸ\nÛ³. Ø¯Ø± ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ø±Ù†Ø§Ù…Ù‡ØŒ Ø¢Ø¯Ø±Ø³ ØµØ­ÛŒØ­ Ø§Ø³ØªØŸ`,
                            isThinking: false
                        };
                    }
                    return msg;
                }));
            } else {
                setMessages(prev => prev.map(msg => {
                    if (msg.id === responseMsgId) {
                        return {
                            ...msg,
                            content: response.text,
                            sources: response.sources,
                            // Fix: response now guaranteed to have isAmbiguous and options from search.ts
                            options: response.isAmbiguous ? response.options : undefined, 
                            debugInfo: response.debugInfo,
                            isThinking: false,
                            // Ensure final state is visible by merging
                            pipelineData: { 
                                ...msg.pipelineData,
                                step: 'generating', 
                                extractedKeywords: response.debugInfo?.extractedKeywords,
                                processingTime: response.debugInfo?.processingTimeMs 
                            }
                        };
                    }
                    return msg;
                }));
            }
        } catch (error) {
            console.error("Error processing query", error);
            // Ensure thinking stops in UI on unexpected error
            setMessages(prev => prev.map(msg => {
                if (msg.id === responseMsgId) {
                    return { ...msg, isThinking: false, content: 'âŒ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´.' };
                }
                return msg;
            }));
        } finally {
            setIsProcessing(false);
            setProcessingType('idle');
            setProcessingStatus('');
        }
    };

    const handleSendMessage = async () => {
        if (!inputText.trim() || isProcessing) return;

        if (customChunks.length === 0) {
            setMessages(prev => [...prev, {
                id: Date.now().toString(),
                role: 'assistant',
                content: 'âš ï¸ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ Ø®Ø§Ù„ÛŒ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ Ø§Ø¨ØªØ¯Ø§ Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù†ÛŒØ¯.',
                timestamp: new Date()
            }]);
            return;
        }

        const userMsg: Message = {
            id: 'msg-u-' + Date.now(),
            role: 'user',
            content: inputText,
            timestamp: new Date(),
        };

        const thinkingMsgId = 'msg-a-' + Date.now();
        const thinkingMsg: Message = {
            id: thinkingMsgId,
            role: 'assistant',
            content: '',
            timestamp: new Date(),
            isThinking: true
        };

        // Combine updates to prevent double render/scroll jump
        setMessages(prev => [...prev, userMsg, thinkingMsg]);
        setInputText('');
        
        // Pass the pre-created ID so we update it instead of creating new one
        await performQuery(userMsg.content, undefined, thinkingMsgId);
    };

    const handleOptionSelect = async (selectedCategory: string) => {
        let lastMsgIndex = -1;
        for (let i = messages.length - 1; i >= 0; i--) {
            if (messages[i].role === 'assistant' && messages[i].options) {
                lastMsgIndex = i;
                break;
            }
        }
        
        if (lastMsgIndex !== -1) {
            setMessages(prev => {
                const next = [...prev];
                next[lastMsgIndex] = { ...next[lastMsgIndex], selectedOption: selectedCategory };
                return next;
            });

            let originalQuery = "";
            for (let i = lastMsgIndex - 1; i >= 0; i--) {
                if (messages[i].role === 'user') {
                    originalQuery = messages[i].content;
                    break;
                }
            }

            if (originalQuery) {
                if (categoryLabels[selectedCategory]) {
                     await performQuery(originalQuery, selectedCategory);
                } else {
                     await performQuery(`${originalQuery} Ø¯Ø± ${selectedCategory}`);
                }
            }
        }
    };

    // --- Fine-Tuning Feedback Logic ---
    const handleFeedback = async (messageId: string, rating: number) => {
        setMessages(prev => prev.map(msg => 
            msg.id === messageId ? { ...msg, feedback: rating } : msg
        ));

        const msgIndex = messages.findIndex(m => m.id === messageId);
        if (msgIndex <= 0) return; 

        const assistantMsg = messages[msgIndex];
        const userMsg = messages[msgIndex - 1];

        if (userMsg.role !== 'user') return; 

        const record: FineTuningRecord = {
            id: `ft-${Date.now()}`,
            prompt: userMsg.content,
            response: assistantMsg.content,
            context: assistantMsg.sources?.map(s => s.snippet).join('\n---\n') || '',
            score: rating,
            sourceIds: assistantMsg.sources?.map(s => s.id) || [],
            model: getSettings().chatModel,
            createdAt: Date.now(),
            updatedAt: Date.now()
        };

        await saveFineTuningRecord(record);
        await updateFineTuningCount();
    };

    const handleExportFineTuning = async () => {
        try {
            const jsonlData = await exportFineTuningDataset();
            const blob = new Blob([jsonlData], { type: 'application/jsonl' });
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = `rayan_rlhf_dataset_${new Date().toISOString().slice(0,10)}.jsonl`;
            document.body.appendChild(a);
            a.click();
            document.body.removeChild(a);
            URL.revokeObjectURL(url);
        } catch (e) {
            alert('Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¯ÛŒØªØ§Ø³Øª Ø¢Ù…ÙˆØ²Ø´ÛŒ');
        }
    };

    const handleCancelProcessing = () => {
        if (abortControllerRef.current) {
            abortControllerRef.current.abort();
        }
        setIsProcessing(false);
        setProcessingType('idle');
        setProcessingStatus('Ø¹Ù…Ù„ÛŒØ§Øª ØªÙˆØ³Ø· Ú©Ø§Ø±Ø¨Ø± Ù„ØºÙˆ Ø´Ø¯.');
        
        setDocsList(prev => prev.map(d => 
            d.status === 'processing' || d.status === 'embedding' 
            ? { ...d, status: 'error' } 
            : d
        ));
    };

    // --- Ticket Ingestion (Isolated) ---
    const handleTicketFileSelected = async (fileList: FileList) => {
        if (fileList.length === 0) return;
        const file = fileList[0];
        
        setIsProcessing(true);
        setProcessingType('file');
        setProcessingStatus(`Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªÛŒÚ©Øªâ€ŒÙ‡Ø§ÛŒ ${file.name}...`);

        try {
            const tickets = await parseTicketFile(file, (step, info) => {
                setProcessingStatus(typeof info === 'string' ? info : `${step}...`);
            });
            
            if (tickets.length > 0) {
                await saveTicketsToDB(tickets);
                setTicketChunks(prev => [...prev, ...tickets]);
                alert(`${tickets.length} ØªÛŒÚ©Øª Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ù‡ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ ØªØ­Ù„ÛŒÙ„ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯.`);
            } else {
                alert('Ù‡ÛŒÚ† ØªÛŒÚ©ØªÛŒ Ø¯Ø± ÙØ§ÛŒÙ„ ÛŒØ§ÙØª Ù†Ø´Ø¯.');
            }
        } catch (e: any) {
            console.error(e);
            alert(`Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªÛŒÚ©Øªâ€ŒÙ‡Ø§: ${e.message}`);
        } finally {
            setIsProcessing(false);
            setProcessingType('idle');
            setProcessingStatus('');
        }
    };

    const handleClearTickets = async () => {
        if (confirm("Ø¢ÛŒØ§ Ø§Ø² Ø­Ø°Ù ØªÙ…Ø§Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªÛŒÚ©Øª Ù…Ø·Ù…Ø¦Ù† Ù‡Ø³ØªÛŒØ¯ØŸ")) {
            await clearTicketsDB();
            setTicketChunks([]);
        }
    };

    // --- Main File Ingestion ---
    const handleFilesSelected = async (fileList: FileList) => {
        const isOnline = await checkOllamaConnection();
        if (!isOnline) {
            alert("Ø®Ø·Ø§: Ø³Ø±ÙˆÛŒØ³ Ollama Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª. Ù„Ø·ÙØ§Ù‹ Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ Ollama Ø§Ø¬Ø±Ø§ Ø´Ø¯Ù‡ Ø§Ø³Øª.");
            return;
        }

        setIsProcessing(true);
        setProcessingType('file');
        setProcessingStatus('Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù†Ø§Ù„ÛŒØ² ÙØ§ÛŒÙ„â€ŒÙ‡Ø§...');
        
        const newDocs: DocumentStatus[] = Array.from(fileList)
            .filter(f => f.name.match(/\.(md|txt|json|csv|xml|js|ts|py|log|docx)$/i)) 
            .map(f => ({
                name: f.name,
                status: 'processing',
                chunks: 0
            }));
        
        if (newDocs.length === 0) {
            alert("Ù‡ÛŒÚ† ÙØ§ÛŒÙ„ Ù‚Ø§Ø¨Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.");
            setIsProcessing(false);
            setProcessingType('idle');
            setProcessingStatus('');
            return;
        }

        setDocsList(prev => [...newDocs, ...prev]);

        abortControllerRef.current = new AbortController();

        try {
            const extractedChunks = await parseFiles(
                fileList, 
                (fileName, step, info) => {
                    if (step === 'complete') {
                        const data = info as { count: number, category: string, subCategory: string };
                        setProcessingStatus(`ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯: ${fileName}`);
                        setDocsList(currentDocs => currentDocs.map(d => {
                            if (d.name === fileName) {
                                return { 
                                    ...d, 
                                    status: data.count > 0 ? 'indexed' : 'error', 
                                    chunks: data.count,
                                    category: data.category as any,
                                    subCategory: data.subCategory
                                };
                            }
                            return d;
                        }));
                    } else if (step === 'error') {
                        if (info !== 'ABORTED') {
                            setProcessingStatus(`Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´: ${fileName}`);
                            setDocsList(currentDocs => currentDocs.map(d => {
                                if (d.name === fileName) return { ...d, status: 'error' };
                                return d;
                            }));
                        }
                    } else {
                        const statusMsg = info ? `${step === 'reading' ? 'Ø¢Ù†Ø§Ù„ÛŒØ²' : 'Ø¨Ø±Ø¯Ø§Ø±Ø³Ø§Ø²ÛŒ'}: ${fileName} (${info})` : `${fileName}...`;
                        setProcessingStatus(statusMsg);
                        setDocsList(currentDocs => currentDocs.map(d => {
                            if (d.name === fileName) {
                                if (d.status === 'indexed') return d;
                                return { ...d, status: step === 'embedding' ? 'embedding' : 'processing' };
                            }
                            return d;
                        }));
                    }
                },
                abortControllerRef.current.signal 
            );

            setCustomChunks(prev => [...prev, ...extractedChunks]);
            
            setMessages(prev => [...prev, {
                id: Date.now().toString(),
                role: 'system',
                content: `âœ… Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯. ${extractedChunks.length} Ù‚Ø·Ø¹Ù‡ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯.`,
                timestamp: new Date()
            }]);

        } catch (e: any) {
            console.error(e);
            if (e.message === "ABORTED") {
                setMessages(prev => [...prev, {
                    id: Date.now().toString(),
                    role: 'system',
                    content: 'ğŸ›‘ Ø¹Ù…Ù„ÛŒØ§Øª Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ ØªÙˆØ³Ø· Ú©Ø§Ø±Ø¨Ø± Ù…ØªÙˆÙ‚Ù Ø´Ø¯.',
                    timestamp: new Date()
                }]);
            } else if (e.message === "OLLAMA_CONNECTION_REFUSED") {
                setMessages(prev => [...prev, {
                    id: Date.now().toString(),
                    role: 'system',
                    content: 'âŒ Ø®Ø·Ø§: Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Ollama Ù‚Ø·Ø¹ Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯ Ú©Ù‡ Ø³Ø±ÙˆÛŒØ³ Ø¯Ø± Ø­Ø§Ù„ Ø§Ø¬Ø±Ø§ Ø¨Ø§Ø´Ø¯ Ùˆ Ù…Ø¬Ø¯Ø¯Ø§Ù‹ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.',
                    timestamp: new Date()
                }]);
            } else {
                alert("Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§");
            }
        } finally {
            setIsProcessing(false);
            setProcessingType('idle');
            setProcessingStatus('');
            abortControllerRef.current = null;
        }
    };

    const handleClearDB = async () => {
        if (confirm('Ø¢ÛŒØ§ Ù…Ø·Ù…Ø¦Ù† Ù‡Ø³ØªÛŒØ¯ØŸ ØªÙ…Ø§Ù… Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡ Ø­Ø°Ù Ø®ÙˆØ§Ù‡Ù†Ø¯ Ø´Ø¯.')) {
            await clearDatabase();
            setCustomChunks([]);
            setTicketChunks([]);
            setDocsList([]);
            setConversations([]);
            setMessages([INITIAL_MESSAGE]);
            setCurrentChatId('new');
            setLastBenchmarkScore(null);
            setFineTuningCount(0);
            alert('Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ Ù¾Ø§Ú© Ø´Ø¯.');
        }
    };

    const handleExportDB = async () => {
        try {
            // Using new blob-optimized export to handle large datasets (18k+ chunks)
            const blob = await exportDatabaseToBlob();
            
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = `rayan_vector_db_${new Date().toISOString().slice(0,10)}.json`;
            document.body.appendChild(a);
            a.click();
            document.body.removeChild(a);
            URL.revokeObjectURL(url);
        } catch (e: any) {
            console.error("Export DB Error:", e);
            alert(`Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¯ÛŒØªØ§Ø¨ÛŒØ³: ${e.message || 'Unknown Error'}. \n(Console Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø¬Ø²Ø¦ÛŒØ§Øª Ú†Ú© Ú©Ù†ÛŒØ¯)`);
        }
    };

    const handleImportDB = async (fileList: FileList) => {
        if (fileList.length === 0) return;
        const file = fileList[0];
        const reader = new FileReader();
        reader.onload = async (e) => {
            try {
                const content = e.target?.result as string;
                setIsDbLoading(true);
                const loadedChunks = await importDatabaseFromJson(content);
                refreshStateFromChunks(loadedChunks);
                setMessages(prev => [...prev, {
                    id: Date.now().toString(),
                    role: 'system',
                    content: `ğŸ“¥ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ Ø§Ø² ÙØ§ÛŒÙ„ ${file.name} Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø´Ø¯ (${loadedChunks.length} Ø±Ú©ÙˆØ±Ø¯).`,
                    timestamp: new Date()
                }]);
            } catch (err) {
                alert("Ø®Ø·Ø§: ÙØ§ÛŒÙ„ Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª ÛŒØ§ Ø³Ø§Ø®ØªØ§Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù‡Ù…Ø®ÙˆØ§Ù†ÛŒ Ù†Ø¯Ø§Ø±Ø¯.");
            } finally {
                setIsDbLoading(false);
            }
        };
        reader.readAsText(file);
    };

    const handleNewChat = () => {
        setCurrentChatId('new');
        setMessages([INITIAL_MESSAGE]);
    };

    const handleSelectConversation = (id: string) => {
        const conv = conversations.find(c => c.id === id);
        if (conv) {
            setCurrentChatId(conv.id);
            setMessages(conv.messages);
        }
    };

    const handleDeleteConversation = async (id: string) => {
        if (confirm('Ù…Ú©Ø§Ù„Ù…Ù‡ Ø­Ø°Ù Ø´ÙˆØ¯ØŸ')) {
            await deleteConversationFromDB(id);
            await loadHistory();
            if (currentChatId === id) {
                handleNewChat();
            }
        }
    };

    return {
        state: {
            messages,
            conversations,
            currentChatId,
            inputText,
            isProcessing,
            processingType,
            isDbLoading,
            processingStatus,
            customChunks,
            ticketChunks, // Expose isolated tickets
            docsList,
            isOllamaOnline,
            useWebSearch,
            lastBenchmarkScore,
            fineTuningCount 
        },
        actions: {
            setInputText,
            handleSendMessage,
            handleOptionSelect,
            handleFilesSelected,
            handleTicketFileSelected, // New action
            handleClearTickets, // New action
            handleCancelProcessing,
            handleClearDB,
            handleExportDB,
            handleImportDB,
            handleNewChat,
            handleSelectConversation,
            handleDeleteConversation,
            setUseWebSearch,
            handleFeedback,       
            handleExportFineTuning 
        }
    };
};
